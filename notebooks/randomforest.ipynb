{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a51dd9",
   "metadata": {},
   "source": [
    "\n",
    "# RandomForest Classifier Pipeline com Scikit-Learn\n",
    "\n",
    "Este notebook organiza o pipeline de machine learning utilizando **RandomForest** para classificação, incluindo:\n",
    "- Pré-processamento de dados (numéricos e categóricos)\n",
    "- Validação cruzada com métricas de avaliação\n",
    "- Importância das variáveis\n",
    "- Predição no conjunto de teste e geração do arquivo de submissão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8fb7d3",
   "metadata": {},
   "source": [
    "## 1. Imports e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3034ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importanto todas as bibliotecas necessárias\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "# para gráficos interativos no Windows\n",
    "matplotlib.use('TkAgg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e802a",
   "metadata": {},
   "source": [
    "## 2. Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c21cac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.join('..', 'data')  # sobe uma pasta e entra em 'data'\n",
    "train_path = os.path.join(BASE_DIR, 'train.csv')\n",
    "test_path = os.path.join(BASE_DIR, 'test.csv')\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3617f53",
   "metadata": {},
   "source": [
    "## 3. Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05462431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# separar features e target\n",
    "X = train_df.drop(columns=['id', 'labels'])\n",
    "y = train_df['labels']\n",
    "X_test = test_df.drop(columns=['id'])\n",
    "\n",
    "# identificar colunas\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = ['category_code']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1fa4a",
   "metadata": {},
   "source": [
    "## 4. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f97135ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transformações numéricas\n",
    "numerical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# transformações categóricas\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# combinação dos preprocessadores\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382fe916",
   "metadata": {},
   "source": [
    "## 5. Definindo o modelo e o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6efa1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    class_weight='balanced', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf_model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f300b1",
   "metadata": {},
   "source": [
    "## 6. Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f339eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics per Fold\n",
      "Fold 1: Accuracy=0.800, F1=0.857, ROC-AUC=0.809\n",
      "Fold 2: Accuracy=0.744, F1=0.822, ROC-AUC=0.765\n",
      "Fold 3: Accuracy=0.752, F1=0.816, ROC-AUC=0.795\n",
      "Fold 4: Accuracy=0.798, F1=0.862, ROC-AUC=0.796\n",
      "Fold 5: Accuracy=0.798, F1=0.854, ROC-AUC=0.867\n",
      "\n",
      "Average Metrics\n",
      "Accuracy : 0.779\n",
      "F1-score : 0.842\n",
      "ROC-AUC  : 0.806\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'f1', 'roc_auc']\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, X, y, cv=cv, \n",
    "    scoring=scoring, \n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validation Metrics per Fold\")\n",
    "for i in range(5):\n",
    "    print(f\"Fold {i+1}: Accuracy={cv_results['test_accuracy'][i]:.3f}, \"\n",
    "          f\"F1={cv_results['test_f1'][i]:.3f}, ROC-AUC={cv_results['test_roc_auc'][i]:.3f}\")\n",
    "\n",
    "print(\"\\nAverage Metrics\")\n",
    "print(f\"Accuracy : {np.mean(cv_results['test_accuracy']):.3f}\")\n",
    "print(f\"F1-score : {np.mean(cv_results['test_f1']):.3f}\")\n",
    "print(f\"ROC-AUC  : {np.mean(cv_results['test_roc_auc']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070b6fe",
   "metadata": {},
   "source": [
    "## 7. Importância das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9d3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofia\\AppData\\Local\\Temp\\ipykernel_33812\\2827649022.py:12: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=feat_imp, x='Importance', y='Feature', palette='mako')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"Feature\": feature_names, \n",
    "    \"Importance\": importances\n",
    "}).sort_values(by='Importance', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=feat_imp, x='Importance', y='Feature', palette='mako')\n",
    "plt.title(\"Top 15 Features - RandomForest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cc923",
   "metadata": {},
   "source": [
    "## 8. Predição no conjunto de teste e submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "824ccaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved at: ..\\data\\submission_randomforest.csv\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.path.join('..', 'data')\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(BASE_DIR, 'test.csv'))\n",
    "X_test = test_df.drop(columns=['id'])\n",
    "test_ids = test_df['id']\n",
    "\n",
    "# fazer previsões\n",
    "test_predictions = pipeline.predict(X_test)\n",
    "\n",
    "# criar DataFrame de submissão\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'labels': test_predictions\n",
    "})\n",
    "\n",
    "# caminho do arquivo de submissão\n",
    "submission_path = os.path.join(BASE_DIR, 'submission_randomforest.csv')\n",
    "\n",
    "# salvar CSV\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved at: {submission_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language": "python",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
